# Nova HTTP Throughput Optimization Plan

**Goal:** ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Nova HTTP throughput ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ

---

## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠ (Bottlenecks Identified)

### 1. **‡∏õ‡∏¥‡∏î Connection ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á** ‚ùå (Impact ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!)

**Problem:**
```cpp
// Line 1407 in BuiltinHTTP.cpp
CLOSE_SOCKET(clientSocket);  // ‚Üê ‡∏õ‡∏¥‡∏î‡∏ó‡∏∏‡∏Å request!
```

**Impact:**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ TCP 3-way handshake ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (~3 RTT overhead)
- ‡πÑ‡∏°‡πà‡∏°‡∏µ connection reuse
- Throughput ‡∏•‡∏î‡∏•‡∏á‡∏°‡∏≤‡∏Å

**Solution:**
- ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ HTTP/1.1 Keep-Alive
- ‡πÄ‡∏Å‡πá‡∏ö connection ‡πÑ‡∏ß‡πâ‡∏£‡∏≠ request ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
- ‡∏õ‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ client ‡∏™‡πà‡∏á `Connection: close` ‡∏´‡∏£‡∏∑‡∏≠ timeout

**Expected Improvement:** **2-5x throughput**

---

### 2. **Blocking I/O** ‚ö†Ô∏è (Impact ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á)

**Problem:**
```cpp
// Line 1353
int bytesRead = recv(clientSocket, buffer, sizeof(buffer) - 1, 0);
```

- ‡πÉ‡∏ä‡πâ blocking recv() ‡πÅ‡∏ö‡∏ö synchronous
- ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ handle concurrent connections ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ

**Solution:**
- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô non-blocking I/O + select/poll
- ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ thread pool ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö concurrent connections

**Expected Improvement:** **3-10x throughput** (for concurrent load)

---

### 3. **Memory Allocation ‡∏ó‡∏∏‡∏Å Request** ‚ö†Ô∏è (Impact ‡∏ô‡πâ‡∏≠‡∏¢)

**Problem:**
```cpp
// Lines 1363, 1373
IncomingMessage* req = new IncomingMessage();
ServerResponse* res = new ServerResponse(clientSocket);
```

- Allocate/deallocate objects ‡∏ó‡∏∏‡∏Å request
- Overhead ‡∏à‡∏≤‡∏Å memory allocation

**Solution:**
- Object pooling - reuse objects
- Pre-allocate buffers

**Expected Improvement:** **10-20% throughput**

---

### 4. **Parsing Overhead** ‚ö†Ô∏è (Impact ‡∏ô‡πâ‡∏≠‡∏¢)

**Problem:**
- Parse HTTP headers ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏°‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô header ‡πÄ‡∏î‡∏¥‡∏°
- String operations ‡∏ä‡πâ‡∏≤

**Solution:**
- Cache parsed results
- Optimize string parsing with SIMD
- Use zero-copy techniques

**Expected Improvement:** **5-15% throughput**

---

## Optimizations ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏° Priority

### üî• Priority 1: Enable Keep-Alive (Must Have!)

**Implementation:**
```cpp
// ‡πÉ‡∏ô acceptOne function
bool keepAlive = true;  // HTTP/1.1 default is keep-alive
char* connectionHeader = req->getHeader("connection");
if (connectionHeader) {
    keepAlive = (strcasecmp(connectionHeader, "close") != 0);
}

if (keepAlive) {
    // Don't close socket, loop back to read next request
    continue_reading_on_same_socket();
} else {
    CLOSE_SOCKET(clientSocket);
}
```

**Estimated Time:** 2-4 hours
**Expected Gain:** **2-5x throughput**

---

### üî• Priority 2: Non-Blocking I/O + Event Loop

**Implementation:**
- ‡πÉ‡∏ä‡πâ `select()` ‡∏´‡∏£‡∏∑‡∏≠ `epoll` (Linux) / `IOCP` (Windows)
- Multiple connections in event loop
- Non-blocking sockets

**Estimated Time:** 1-2 days
**Expected Gain:** **3-10x throughput** (concurrent)

---

### ‚ö° Priority 3: Object Pooling

**Implementation:**
```cpp
// Object pool
std::vector<IncomingMessage*> reqPool;
std::vector<ServerResponse*> resPool;

IncomingMessage* getReq() {
    if (reqPool.empty()) return new IncomingMessage();
    auto req = reqPool.back();
    reqPool.pop_back();
    req->reset();
    return req;
}

void returnReq(IncomingMessage* req) {
    reqPool.push_back(req);
}
```

**Estimated Time:** 2-4 hours
**Expected Gain:** **10-20% throughput**

---

### ‚ö° Priority 4: Optimize Parsing

**Implementation:**
- Use faster string parsing
- Avoid unnecessary allocations
- Use string_view instead of string copies

**Estimated Time:** 4-8 hours
**Expected Gain:** **5-15% throughput**

---

## ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

### ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:

1. **Apache Bench (ab)**
```bash
ab -n 10000 -c 100 http://localhost:3000/
```

2. **wrk** (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ ab)
```bash
wrk -t4 -c100 -d30s http://localhost:3000/
```

3. **hey** (Go-based)
```bash
hey -n 10000 -c 100 http://localhost:3000/
```

### Test Cases:

1. **Low Concurrency** (c=1): ‡∏ß‡∏±‡∏î latency ‡πÅ‡∏•‡∏∞ single-thread performance
2. **Medium Concurrency** (c=50): ‡∏ß‡∏±‡∏î typical load
3. **High Concurrency** (c=500): ‡∏ß‡∏±‡∏î maximum capacity
4. **Sustained Load** (30-60s): ‡∏ß‡∏±‡∏î memory leaks ‡πÅ‡∏•‡∏∞ stability

---

## ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

### ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ (Before Optimization):
```
Sequential Test (Python client):
- Throughput: 8.26 req/sec
- Bottleneck: Client sending requests one-by-one

Concurrent Test (expected with ab -c100):
- Throughput: ~100-200 req/sec (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì, ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ test)
- Bottleneck: Close socket every request
```

### ‡∏´‡∏•‡∏±‡∏á Priority 1 (Keep-Alive):
```
Concurrent Test (ab -c100):
- Throughput: ~500-1000 req/sec
- Gain: 2-5x
- Competitive with Node.js
```

### ‡∏´‡∏•‡∏±‡∏á Priority 2 (Non-Blocking I/O):
```
Concurrent Test (ab -c100):
- Throughput: ~2000-5000 req/sec
- Gain: 10-25x from baseline
- Competitive with Bun
```

### ‡∏´‡∏•‡∏±‡∏á Priority 3+4 (Object Pool + Parsing):
```
Concurrent Test (ab -c100):
- Throughput: ~3000-8000 req/sec
- Gain: 15-40x from baseline
- Potentially faster than Node.js
```

---

## ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞ Next Steps

### ‡∏ó‡∏≥‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ (Quick Wins):

1. **Test with `ab` or `wrk`** - ‡∏£‡∏π‡πâ throughput ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ
2. **Implement Keep-Alive** - ‡πÑ‡∏î‡πâ 2-5x ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
3. **Re-test and compare** - ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Node/Bun

### ‡∏ó‡∏≥‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (Bigger Wins):

4. **Non-blocking I/O** - Scale to thousands of concurrent connections
5. **Object pooling** - Reduce GC-like overhead
6. **SIMD parsing** - Ultra-fast header parsing

---

## Realistic Target

**Short-term (1-2 days):**
- Nova: 500-1000 req/sec (with keep-alive)
- Node: 500-800 req/sec
- Bun: 800-1200 req/sec

**Result:** Nova competitive with Node, slightly behind Bun

**Medium-term (1 week):**
- Nova: 2000-5000 req/sec (with non-blocking I/O)
- Node: 800-1500 req/sec
- Bun: 1200-2000 req/sec

**Result:** Nova potentially faster than both!

---

## Key Insight

**‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô**: Nova infrastructure ‡∏î‡∏µ (compiler, runtime) ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà optimize ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö throughput

**‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï**: Nova ‡∏°‡∏µ potential ‡∏™‡∏π‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞:
- Native compilation (no JIT overhead)
- No garbage collection pauses
- LLVM optimizations
- Direct syscall access

**With proper optimizations, Nova can beat Node.js and compete with Bun!** üöÄ

---

*Document Created: December 3, 2025*
*Status: Bottlenecks identified, optimizations planned*
*Next Action: Implement Keep-Alive (2-4 hours, 2-5x gain)*
